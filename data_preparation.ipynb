{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d316110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, ccf\n",
    "from math import ceil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import holidays\n",
    "\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b2d20",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57688f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_en_data(df, df_name):\n",
    "    sampfreqsec_2_str = {\n",
    "        900:\"15min\",\n",
    "        1800:\"30min\",\n",
    "        3600:\"1h\",\n",
    "    }\n",
    "        \n",
    "    df = df.copy()\n",
    "    \n",
    "    n_dup = df.duplicated().sum()\n",
    "        \n",
    "    if n_dup > 0:\n",
    "        df = df.drop_duplicates()\n",
    "    \n",
    "    n_df_pre_reindex = len(df)\n",
    "    sampfreqsec = df[\"datetime\"].diff()[1:].describe()['50%'].seconds\n",
    "    new_index = pd.date_range(df['datetime'].min(), df['datetime'].max(),freq=sampfreqsec_2_str[sampfreqsec])\n",
    "    n_new_index = len(new_index)   \n",
    "    df = df.set_index(\"datetime\")\n",
    "    \n",
    "    if n_df_pre_reindex != n_new_index:\n",
    "        # Missing data entries, need to reindex\n",
    "        df = df.reindex(new_index)\n",
    "\n",
    "    if sampfreqsec_2_str[sampfreqsec] != \"1h\":\n",
    "        if df_name == \"generation_forecast\":\n",
    "            df = df.resample('1h',closed='right', label='right').mean()\n",
    "        else:\n",
    "            df = df.resample('1h',closed='right', label='right').sum()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def prepare_en_data(df_names):\n",
    "    \n",
    "    print(\"Preparing Energy Data\")\n",
    "    \n",
    "    dfs = {}\n",
    "\n",
    "    for df_name in df_names:\n",
    "        dfs[df_name] = pd.read_csv(f\".\\\\data\\\\{df_name}_NL.csv\") \n",
    "        dfs[df_name][\"datetime\"] = pd.to_datetime(dfs[df_name][\"datetime\"], utc=True).dt.tz_localize(None)\n",
    "        dfs[df_name] = dfs[df_name].sort_values('datetime')\n",
    "        dfs[df_name] = clean_en_data(dfs[df_name], df_name)\n",
    "\n",
    "    # remove Hydro Run-of-river and poundage from generation\n",
    "    dfs[\"generation\"] = dfs[\"generation\"].drop('Hydro Run-of-river and poundage', axis=1)\n",
    "    # Add generation prefix to generation adn wind_solar_forecast columns\n",
    "    dfs[\"generation\"] = dfs[\"generation\"].add_prefix(\"generation_\")\n",
    "    dfs[\"wind_solar_forecast\"] = dfs[\"wind_solar_forecast\"].add_prefix(\"generation_forecast_\")\n",
    "    \n",
    "    check = 0\n",
    "    for i, df_name in enumerate(df_names):\n",
    "        temp_n = len(dfs[df_name])\n",
    "        if i == 0:\n",
    "            df = dfs[df_name].copy()\n",
    "        elif i > 0 and temp_n != check:\n",
    "            print(f\"Different number of rows in {df_name}({temp_n}) vs {df_names[i-1]}({check})\")\n",
    "            return pd.DataFrame()\n",
    "        else:\n",
    "            df = pd.merge_asof(df,  dfs[df_name], left_index=True, right_index=True)\n",
    "            \n",
    "        check = temp_n\n",
    "        \n",
    "    # set outliers to null and interpolate    \n",
    "    outlier_ind = df[df[\"generation_Waste\"] < 0.0].index\n",
    "    df.loc[outlier_ind, \"generation_Waste\"] = np.nan\n",
    "    df.interpolate(method='linear', limit_direction='forward', inplace=True)\n",
    "    \n",
    "    # calculate total generation\n",
    "    generation_columns = [col for col in df.columns if (\"generation_\" in col) and (\"missing_\" not in col)]\n",
    "    df[\"generation_total\"] = df[generation_columns].sum(axis=1)\n",
    "    \n",
    "    # Calculate residual load and drop actual load\n",
    "    df[\"generation_renewable\"] = df[[\"generation_Solar\", \"generation_Wind Offshore\", \"generation_Wind Onshore\"]].sum(axis=1)\n",
    "    df[\"residual_load\"] = df[\"Actual Load\"].sub(df[\"generation_renewable\"])\n",
    "    df = df.drop([\"generation_renewable\", \"Actual Load\"], axis=1)\n",
    "    \n",
    "    # Combine generation_Wind variables and drop actual load\n",
    "    df[\"generation_Wind\"] = df[[\"generation_Wind Offshore\", \"generation_Wind Onshore\"]].sum(axis=1)\n",
    "    df = df.drop([\"generation_Wind Offshore\", \"generation_Wind Onshore\"], axis=1)\n",
    "    \n",
    "    # Combine generation_forecast_Wind variables and drop actual load\n",
    "    df[\"generation_forecast_Wind\"] = df[[\"generation_forecast_Wind Onshore\", \"generation_forecast_Wind Offshore\"]].sum(axis=1)\n",
    "    df = df.drop([\"generation_forecast_Wind Onshore\", \"generation_forecast_Wind Offshore\"], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_elec_consumption_by_city(cities):\n",
    "    path = \".\\\\data\\\\Electricity\"\n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f)) and ('2020' in f)]\n",
    "\n",
    "    df_en = []\n",
    "\n",
    "    for f in onlyfiles:\n",
    "        df_en.append(pd.read_csv(f))\n",
    "\n",
    "    df_en = pd.concat(df_en, ignore_index=True)\n",
    "    df_en['city'] = df_en['city'].str.lower()\n",
    "    df_en = df_en.groupby('city')['annual_consume'].sum().sort_values(ascending=False)\n",
    "    df_en = df_en.rename(index={\"'s-gravenhage\":\"the hague\"})\n",
    "    df_en = df_en[cities]\n",
    "    dict_en = df_en.to_dict()\n",
    "    \n",
    "    return dict_en\n",
    "\n",
    "def create_weighted_variables(df, corr_features, cities):\n",
    "    \n",
    "    dict_weights = get_elec_consumption_by_city(cities)\n",
    "    cols_2_remove = []\n",
    "\n",
    "    for feature in corr_features:\n",
    "        temp_weighted = 0.0\n",
    "        total_weight = 0.0\n",
    "        for city in cities:\n",
    "            if f\"{feature}_{city}\" in df.columns:\n",
    "                cols_2_remove.append(f\"{feature}_{city}\")\n",
    "                weight = dict_weights[city]\n",
    "                total_weight += weight\n",
    "                temp_weighted += weight * df[f\"{feature}_{city}\"]\n",
    "        temp_weighted = temp_weighted / total_weight\n",
    "        df[f\"{feature}_weighted\"] = temp_weighted\n",
    "        \n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def prepare_weather_data(min_datetime, max_datetime):\n",
    "    \n",
    "    print(\"Preparing Weather Data\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(\".\\\\data\\\\weather_data_NL.csv\")\n",
    "    df = df.rename(columns={\"dt\":\"datetime\"})\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], unit='s')\n",
    "    df[\"city_name\"] = df[\"city_name\"].str.lower()\n",
    "    df = df[(df[\"datetime\"] >= min_datetime) & (df[\"datetime\"] <= max_datetime)].copy()\n",
    "    df = df.sort_values(['datetime','city_name'])\n",
    "        \n",
    "    # remove irrevalant columns\n",
    "    cols_2_remove = ['dt_iso', 'timezone', 'lat', 'lon', 'weather_icon', 'weather_id', 'weather_main', 'weather_description',\n",
    "                     'visibility', 'wind_deg', 'clouds_all', 'feels_like', 'temp_min', 'temp_max']\n",
    "    \n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "    # remove features with majority null values\n",
    "    df_pct_null = df.isna().sum() / len(df)\n",
    "    cols_2_remove = list(df_pct_null[df_pct_null > 0.5].index)\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "    # remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    count_by_city = df.groupby('city_name').size()\n",
    "    \n",
    "    # check that there are the same number of records per city\n",
    "    for i in range(len(count_by_city)):\n",
    "        if i > 0 and count_by_city.iloc[i] != count_by_city.iloc[0]:\n",
    "            city1, count1 = count_by_city.index[i-1], count_by_city.iloc[i-1]\n",
    "            city2, count2 = count_by_city.index[i], count_by_city.iloc[i]\n",
    "            print(f\"Different number of records for {city1}({count1}) vs {city2}({count2})\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    df = df.set_index(\"datetime\")\n",
    "    \n",
    "    # set outliers to null\n",
    "    outlier_ind = []\n",
    "    outlier_ind.append((df['city_name'] == \"utrecht\") & (df['wind_speed'] > 21) & (df.index >= '2021-01-24') & (df.index <= '2021-01-26'))\n",
    "    outlier_ind.append((df['city_name'] == \"utrecht\") & (df['wind_speed'] > 21) & (df.index >= '2021-03-10') & (df.index <= '2021-03-20'))\n",
    "    outlier_ind.append((df['city_name'] == \"eindhoven\") & (df['wind_speed'] > 10) & (df.index >= '2022-11-16') & (df.index <= '2022-11-25'))\n",
    "    outlier_ind.append((df['city_name'] == \"eindhoven\") & (df['wind_speed'] > 15) & (df.index >= '2023-01-13') & (df.index <= '2023-01-15'))\n",
    "    outlier_ind.append((df['humidity'] < 18))   \n",
    "    outlier_cols = [\"wind_speed\", \"wind_speed\", \"wind_speed\", \"wind_speed\", [\"dew_point\", \"humidity\"]]\n",
    " \n",
    "    for ind, cols in zip(outlier_ind, outlier_cols):\n",
    "        df.loc[ind, cols] = np.nan\n",
    "        \n",
    "    cities = df[\"city_name\"].unique()\n",
    "\n",
    "    # create seperate column per feature and city                  \n",
    "    for i, city in enumerate(cities):\n",
    "        temp_df = df[df[\"city_name\"] == city].copy()\n",
    "        temp_df = temp_df.drop(\"city_name\", axis=1)\n",
    "        temp_df = temp_df.sort_index()\n",
    "        temp_df = temp_df.add_suffix(f'_{city}')\n",
    "        if i == 0:\n",
    "            df_wide = temp_df\n",
    "        else:\n",
    "            df_wide = pd.merge(df_wide, temp_df, left_index=True, how='left', right_index=True)\n",
    "\n",
    "    df = df_wide.copy()\n",
    "    \n",
    "    del df_wide\n",
    "                    \n",
    "    # remove features with majority null values\n",
    "    df_pct_null = df.isna().sum() / len(df)\n",
    "    cols_2_remove = list(df_pct_null[df_pct_null > 0.5].index)\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "                       \n",
    "    # interpolate remaining features          \n",
    "    df.interpolate(method='linear', limit_direction='forward', inplace=True)    \n",
    "    \n",
    "#     # create temperature ranges per city and remove feels_like*, temp_min*, temp_max*\n",
    "#     fl_features = [f\"feels_like_{city}\" for city in cities if f\"feels_like_{city}\" in df.columns]\n",
    "#     tmin_features = [f\"temp_min_{city}\" for city in cities if f\"temp_min_{city}\" in df.columns]\n",
    "#     tmax_features = [f\"temp_max_{city}\" for city in cities if f\"temp_max_{city}\" in df.columns]\n",
    "#     df_temp_range = df[tmax_features].sub(df[tmin_features].rename(columns=dict(zip(tmin_features, tmax_features))))\n",
    "#     df_temp_range.columns = [col.replace(\"temp_max\", \"temp_rng\") for col in df_temp_range.columns]\n",
    "#     df = df.drop(fl_features + tmin_features + tmax_features, axis=1)  \n",
    "#     df = pd.merge(df, df_temp_range, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # Create weighted variable from highly correlated variables per city \n",
    "    corr_features = [\"dew_point\", \"temp\", \"pressure\", \"humidity\", \"wind_speed\"]\n",
    "    df =  create_weighted_variables(df, corr_features, cities)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_unav_gen_data(df_names):\n",
    "    \n",
    "    print(\"Preparing Unavailable Generation Data\")\n",
    "    \n",
    "    for i, df_name in enumerate(df_names):\n",
    "        temp_df = pd.read_csv( f\".\\\\data\\\\unavailability_of_generation_units_NL_{df_name}.csv\") \n",
    "        temp_df[\"datetime\"] = pd.to_datetime(temp_df[\"datetime\"], utc=True).dt.tz_localize(None)\n",
    "        temp_df = temp_df.sort_values('datetime').set_index('datetime')\n",
    "        if i == 0:\n",
    "            df = temp_df.copy()\n",
    "        else:\n",
    "            df = pd.merge(df, temp_df, left_index=True, how='left', right_index=True)\n",
    "            \n",
    "    return df.fillna(0)\n",
    "\n",
    "def generate_calendar_features(df):\n",
    "    df = df.copy()\n",
    "    print(\"Adding Calendar Features\")\n",
    "    df[\"hour_of_day\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"day_of_week\"] = df[\"datetime\"].dt.dayofweek\n",
    "    df[\"weekend\"] = np.where((df[\"day_of_week\"] == 5) | (df[\"day_of_week\"] == 6), 1, 0)\n",
    "    df[\"month\"] = df[\"datetime\"].dt.month\n",
    "    # add variables for holidays\n",
    "    nl_holidays = holidays.NL() \n",
    "    df[\"holiday\"] = df[\"datetime\"].dt.date.apply(lambda x: nl_holidays.get(x)).values\n",
    "    df[\"is_holiday\"] = np.where(df[\"holiday\"].isna(), 0, 1)\n",
    "    df = pd.get_dummies(df, columns=[\"holiday\"], dummy_na=False)\n",
    "    df = df.drop([\"holiday_Bevrijdingsdag\", \"holiday_Koningsdag\"], axis=1)\n",
    "    holiday_cols = [col for col in df.columns if \"holiday_\" in col]\n",
    "    for col in holiday_cols:\n",
    "        df[col] = np.where(df[col], 1, 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_RLI_features(df, horizons):\n",
    "    df = df.copy()\n",
    "    print(\"Adding Relative Load Indicator Features\")\n",
    "    for h in horizons:\n",
    "        temp_residual_load_rs = df[\"residual_load\"].rolling(window=h,min_periods=h).sum().shift(1)\n",
    "        df[f\"RLI_{h}\"] = 100 * df[\"residual_load\"].div(temp_residual_load_rs)\n",
    "        del temp_residual_load_rs\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_lagged_features(df, features, lags):\n",
    "    lagged_data = []\n",
    "    for feature in features:\n",
    "        for lag in lags:\n",
    "            # df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "            lagged_data.append(df[feature].shift(lag))\n",
    "            lagged_data[-1].name = f'{feature}_lag_{lag}'\n",
    "\n",
    "    df = pd.concat([df] + lagged_data, axis=1)\n",
    "\n",
    "    return df.copy()\n",
    "\n",
    "def feature_generation(df):\n",
    "    df = df.reset_index()\n",
    "    df = generate_calendar_features(df)\n",
    "    df = generate_RLI_features(df, [24, 48, 120, 168])\n",
    "    lags = [120]\n",
    "#     lags = [24 * i for i in range(1,8)]\n",
    "    print(\"Adding Lagged day_ahead_prices\")\n",
    "    df = generate_lagged_features(df, [\"day_ahead_prices\"], lags)\n",
    "    \n",
    "    features = [\n",
    "        'generation_Biomass',\n",
    "        'generation_Fossil Gas', 'generation_Fossil Hard coal',\n",
    "        'generation_Nuclear', 'generation_Other', 'generation_Solar',\n",
    "        'generation_Waste', 'crossborder_flow_net', 'imports',\n",
    "        'Forecasted Load', 'generation_forecast', 'generation_forecast_Solar',\n",
    "        'generation_total', 'residual_load', 'generation_Wind',\n",
    "        'generation_forecast_Wind', \n",
    "        'dew_point_weighted', 'temp_weighted', 'pressure_weighted',\n",
    "        'humidity_weighted', 'wind_speed_weighted',\n",
    "        'generation_fossil_gas_missing_qty',\n",
    "        'generation_fossil_hard_coal_missing_qty',\n",
    "        'generation_nuclear_missing_qty'\n",
    "    ]\n",
    "    lags = [24, 48, 72, 96, 120]\n",
    "    print(\"Adding Lagged covariates\")\n",
    "    df = generate_lagged_features(df, features, lags)\n",
    "    # Negatively shift prices by 48hours so we forecast 48 hours into the future\n",
    "    print(\"Adding leading day_ahead_returns as target\")\n",
    "    df['day_ahead_prices_lead_48'] = df['day_ahead_prices'].shift(-48)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bbb7292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Data Preparation\n",
      "####################\n",
      "\n",
      "Preparing Energy Data\n",
      "Preparing Weather Data\n",
      "Preparing Unavailable Generation Data\n",
      "Merging Data\n",
      "\n",
      "Data Quality\n",
      "                                         pct_nulls  pct_zeros\n",
      "day_ahead_prices                               0.0        0.0\n",
      "generation_Biomass                             0.0       10.0\n",
      "generation_Fossil Gas                          0.0        0.0\n",
      "generation_Fossil Hard coal                    0.0        0.0\n",
      "generation_Nuclear                             0.0        0.0\n",
      "generation_Other                               0.0        0.0\n",
      "generation_Solar                               0.0       10.0\n",
      "generation_Waste                               0.0        0.0\n",
      "crossborder_flow_net                           0.0        0.0\n",
      "imports                                        0.0        0.0\n",
      "Forecasted Load                                0.0        0.0\n",
      "generation_forecast                            0.0        0.0\n",
      "generation_forecast_Solar                      0.0       40.0\n",
      "generation_total                               0.0        0.0\n",
      "residual_load                                  0.0        0.0\n",
      "generation_Wind                                0.0        0.0\n",
      "generation_forecast_Wind                       0.0        0.0\n",
      "dew_point_weighted                             0.0        0.0\n",
      "temp_weighted                                  0.0        0.0\n",
      "pressure_weighted                              0.0        0.0\n",
      "humidity_weighted                              0.0        0.0\n",
      "wind_speed_weighted                            0.0        0.0\n",
      "generation_fossil_gas_missing_qty              0.0        0.0\n",
      "generation_fossil_hard_coal_missing_qty        0.0       20.0\n",
      "generation_nuclear_missing_qty                 0.0       90.0\n",
      "####################\n",
      "Feature Generation\n",
      "####################\n",
      "\n",
      "Adding Calendar Features\n",
      "Adding Relative Load Indicator Features\n",
      "Adding Lagged day_ahead_prices\n",
      "Adding Lagged covariates\n",
      "Adding leading day_ahead_returns as target\n"
     ]
    }
   ],
   "source": [
    "en_names = [    \n",
    "    \"day_ahead_prices\",\n",
    "    \"load\",\n",
    "    \"generation\",\n",
    "    \"crossborder_flow_net\",\n",
    "    \"imports\",\n",
    "    \"load_forecast\",\n",
    "    \"generation_forecast\",\n",
    "    \"wind_solar_forecast\",\n",
    "]\n",
    "\n",
    "gen_names = [    \n",
    "    \"fossil_gas\",\n",
    "    \"fossil_hard_coal\",\n",
    "    \"nuclear\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "print(\"#\" * 20)\n",
    "print(\"Data Preparation\")\n",
    "print(\"#\" * 20)\n",
    "print(\"\")\n",
    "dfs.append(prepare_en_data(en_names))\n",
    "dfs.append(prepare_weather_data(dfs[0].index.min(), dfs[0].index.max()))\n",
    "dfs.append(prepare_unav_gen_data(gen_names))\n",
    "\n",
    "print(\"Merging Data\")\n",
    "for i, temp_df in enumerate(dfs):\n",
    "    if i == 0:\n",
    "        df = temp_df.copy()\n",
    "    else:\n",
    "        df = pd.merge(df, temp_df, left_index=True, how='left', right_index=True)\n",
    "\n",
    "print(\"\\nData Quality\")\n",
    "df_nulls_zeros = pd.DataFrame()\n",
    "df_nulls_zeros[\"pct_nulls\"] = 100 * (df.isna().sum() / len(df)).to_frame().round(1)\n",
    "df_nulls_zeros[\"pct_zeros\"] = 100 * ((df == 0).sum() / len(df)).to_frame().round(1)\n",
    "print(df_nulls_zeros)\n",
    "\n",
    "print(\"#\" * 20)\n",
    "print(\"Feature Generation\")\n",
    "print(\"#\" * 20)\n",
    "print(\"\")\n",
    "df = feature_generation(df)\n",
    "\n",
    "df.to_csv(\".\\\\data\\\\prepped_data_NL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcea93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                                           2020-01-08 00:00:00\n",
       "day_ahead_prices                                                 25.77\n",
       "generation_Biomass                                                38.0\n",
       "generation_Fossil Gas                                          12153.0\n",
       "generation_Fossil Hard coal                                     3548.0\n",
       "generation_Nuclear                                              1940.0\n",
       "generation_Other                                               12485.0\n",
       "generation_Solar                                                   0.0\n",
       "generation_Waste                                                1700.0\n",
       "crossborder_flow_net                                            -570.0\n",
       "imports                                                         2242.0\n",
       "Forecasted Load                                                38452.0\n",
       "generation_forecast                                             7616.0\n",
       "generation_forecast_Solar                                          0.0\n",
       "generation_total                                               60990.0\n",
       "residual_load                                                  38488.0\n",
       "generation_Wind                                                 9051.0\n",
       "generation_forecast_Wind                                       12459.0\n",
       "dew_point_weighted                                            7.229477\n",
       "temp_weighted                                                 8.230076\n",
       "pressure_weighted                                          1020.134436\n",
       "humidity_weighted                                            93.467226\n",
       "wind_speed_weighted                                           9.046362\n",
       "generation_fossil_gas_missing_qty                               6135.0\n",
       "generation_fossil_hard_coal_missing_qty                         1693.0\n",
       "generation_nuclear_missing_qty                                     0.0\n",
       "hour_of_day                                                          0\n",
       "day_of_week                                                          2\n",
       "weekend                                                              0\n",
       "month                                                                1\n",
       "is_holiday                                                           0\n",
       "holiday_Eerste Kerstdag                                              0\n",
       "holiday_Eerste Pinksterdag                                           0\n",
       "holiday_Eerste paasdag                                               0\n",
       "holiday_Hemelvaartsdag                                               0\n",
       "holiday_Nieuwjaarsdag                                                0\n",
       "holiday_Tweede Kerstdag                                              0\n",
       "holiday_Tweede Pinksterdag                                           0\n",
       "holiday_Tweede paasdag                                               0\n",
       "RLI_24                                                        3.081836\n",
       "RLI_48                                                        1.544339\n",
       "RLI_168                                                       0.468355\n",
       "day_ahead_prices_lag_120                                          27.7\n",
       "generation_Biomass_lag_120                                        40.0\n",
       "generation_Fossil Gas_lag_120                                  17981.0\n",
       "generation_Fossil Hard coal_lag_120                             3511.0\n",
       "generation_Nuclear_lag_120                                      1940.0\n",
       "generation_Other_lag_120                                       10052.0\n",
       "generation_Solar_lag_120                                          -2.0\n",
       "generation_Waste_lag_120                                        1659.0\n",
       "crossborder_flow_net_lag_120                                     -63.0\n",
       "imports_lag_120                                                 2307.0\n",
       "Forecasted Load_lag_120                                        37886.0\n",
       "generation_forecast_lag_120                                     7314.0\n",
       "generation_forecast_Solar_lag_120                                  0.0\n",
       "generation_total_lag_120                                       61890.0\n",
       "residual_load_lag_120                                          37948.0\n",
       "generation_Wind_lag_120                                         8045.0\n",
       "generation_forecast_Wind_lag_120                               11350.0\n",
       "dew_point_weighted_lag_120                                     6.12966\n",
       "temp_weighted_lag_120                                         7.560493\n",
       "pressure_weighted_lag_120                                  1017.126675\n",
       "humidity_weighted_lag_120                                    90.649157\n",
       "wind_speed_weighted_lag_120                                   7.014854\n",
       "generation_fossil_gas_missing_qty_lag_120                       4185.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_120                 1070.0\n",
       "generation_nuclear_missing_qty_lag_120                             0.0\n",
       "day_ahead_prices_lead_48                                          27.6\n",
       "Name: 168, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
