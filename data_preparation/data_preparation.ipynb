{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d316110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import holidays\n",
    "\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b2d20",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57688f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_en_data(df, df_name):\n",
    "    sampfreqsec_2_str = {\n",
    "        900: \"15min\",\n",
    "        1800: \"30min\",\n",
    "        3600: \"1h\",\n",
    "    }\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    n_dup = df.duplicated().sum()\n",
    "\n",
    "    if n_dup > 0:\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "    n_df_pre_reindex = len(df)\n",
    "    sampfreqsec = df[\"datetime\"].diff()[1:].describe()['50%'].seconds\n",
    "    new_index = pd.date_range(df['datetime'].min(), df['datetime'].max(), freq=sampfreqsec_2_str[sampfreqsec])\n",
    "    n_new_index = len(new_index)\n",
    "    df = df.set_index(\"datetime\")\n",
    "\n",
    "    if n_df_pre_reindex != n_new_index:\n",
    "        # Missing data entries, need to reindex\n",
    "        df = df.reindex(new_index)\n",
    "\n",
    "    if sampfreqsec_2_str[sampfreqsec] != \"1h\":\n",
    "        if df_name == \"generation_forecast\":\n",
    "            df = df.resample('1h', closed='right', label='right').mean()\n",
    "        else:\n",
    "            df = df.resample('1h', closed='right', label='right').sum()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_en_data(df_names):\n",
    "    print(\"Preparing Energy Data\")\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for df_name in df_names:\n",
    "        dfs[df_name] = pd.read_csv(f\".\\\\data\\\\{df_name}_NL.csv\")\n",
    "        dfs[df_name][\"datetime\"] = pd.to_datetime(dfs[df_name][\"datetime\"], utc=True).dt.tz_localize(None)\n",
    "        dfs[df_name] = dfs[df_name].sort_values('datetime')\n",
    "        dfs[df_name] = clean_en_data(dfs[df_name], df_name)\n",
    "\n",
    "    # remove Hydro Run-of-river and poundage from generation\n",
    "    dfs[\"generation\"] = dfs[\"generation\"].drop('Hydro Run-of-river and poundage', axis=1)\n",
    "    # Add generation prefix to generation adn wind_solar_forecast columns\n",
    "    dfs[\"generation\"] = dfs[\"generation\"].add_prefix(\"generation_\")\n",
    "    dfs[\"wind_solar_forecast\"] = dfs[\"wind_solar_forecast\"].add_prefix(\"generation_forecast_\")\n",
    "\n",
    "    check = 0\n",
    "    for i, df_name in enumerate(df_names):\n",
    "        temp_n = len(dfs[df_name])\n",
    "        if i == 0:\n",
    "            df = dfs[df_name].copy()\n",
    "        elif i > 0 and temp_n != check:\n",
    "            print(f\"Different number of rows in {df_name}({temp_n}) vs {df_names[i - 1]}({check})\")\n",
    "            return pd.DataFrame()\n",
    "        else:\n",
    "            df = pd.merge_asof(df, dfs[df_name], left_index=True, right_index=True)\n",
    "\n",
    "        check = temp_n\n",
    "\n",
    "    # set outliers to null and interpolate\n",
    "    outlier_ind = df[df[\"generation_Waste\"] < 0.0].index\n",
    "    df.loc[outlier_ind, \"generation_Waste\"] = np.nan\n",
    "    df.interpolate(method='linear', limit_direction='forward', inplace=True)\n",
    "\n",
    "    # calculate total generation\n",
    "    generation_columns = [col for col in df.columns if (\"generation_\" in col) and (\"missing_\" not in col)]\n",
    "    df[\"generation_total\"] = df[generation_columns].sum(axis=1)\n",
    "\n",
    "    # Calculate residual load and drop actual load\n",
    "    df[\"generation_renewable\"] = df[[\"generation_Solar\", \"generation_Wind Offshore\", \"generation_Wind Onshore\"]].sum(\n",
    "        axis=1)\n",
    "    df[\"residual_load\"] = df[\"Actual Load\"].sub(df[\"generation_renewable\"])\n",
    "    df = df.drop([\"generation_renewable\", \"Actual Load\"], axis=1)\n",
    "\n",
    "    # Combine generation_Wind variables and drop actual load\n",
    "    df[\"generation_Wind\"] = df[[\"generation_Wind Offshore\", \"generation_Wind Onshore\"]].sum(axis=1)\n",
    "    df = df.drop([\"generation_Wind Offshore\", \"generation_Wind Onshore\"], axis=1)\n",
    "\n",
    "    # Combine generation_forecast_Wind variables and drop actual load\n",
    "    df[\"generation_forecast_Wind\"] = df[[\"generation_forecast_Wind Onshore\", \"generation_forecast_Wind Offshore\"]].sum(\n",
    "        axis=1)\n",
    "    df = df.drop([\"generation_forecast_Wind Onshore\", \"generation_forecast_Wind Offshore\"], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_elec_consumption_by_city(cities):\n",
    "    path = \".\\\\data\\\\Electricity\"\n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f)) and ('2020' in f)]\n",
    "\n",
    "    df_en = []\n",
    "\n",
    "    for f in onlyfiles:\n",
    "        df_en.append(pd.read_csv(f))\n",
    "\n",
    "    df_en = pd.concat(df_en, ignore_index=True)\n",
    "    df_en['city'] = df_en['city'].str.lower()\n",
    "    df_en = df_en.groupby('city')['annual_consume'].sum().sort_values(ascending=False)\n",
    "    df_en = df_en.rename(index={\"'s-gravenhage\": \"the hague\"})\n",
    "    df_en = df_en[cities]\n",
    "    dict_en = df_en.to_dict()\n",
    "\n",
    "    return dict_en\n",
    "\n",
    "\n",
    "def create_weighted_variables(df, corr_features, cities):\n",
    "    dict_weights = get_elec_consumption_by_city(cities)\n",
    "    cols_2_remove = []\n",
    "\n",
    "    for feature in corr_features:\n",
    "        temp_weighted = 0.0\n",
    "        total_weight = 0.0\n",
    "        for city in cities:\n",
    "            if f\"{feature}_{city}\" in df.columns:\n",
    "                cols_2_remove.append(f\"{feature}_{city}\")\n",
    "                weight = dict_weights[city]\n",
    "                total_weight += weight\n",
    "                temp_weighted += weight * df[f\"{feature}_{city}\"]\n",
    "        temp_weighted = temp_weighted / total_weight\n",
    "        df[f\"{feature}_weighted\"] = temp_weighted\n",
    "\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_weather_data(min_datetime, max_datetime):\n",
    "    print(\"Preparing Weather Data\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(\".\\\\data\\\\weather_data_NL.csv\")\n",
    "    df = df.rename(columns={\"dt\": \"datetime\"})\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], unit='s')\n",
    "    df[\"city_name\"] = df[\"city_name\"].str.lower()\n",
    "    df = df[(df[\"datetime\"] >= min_datetime) & (df[\"datetime\"] <= max_datetime)].copy()\n",
    "    df = df.sort_values(['datetime', 'city_name'])\n",
    "\n",
    "    # remove irrevalant columns\n",
    "    cols_2_remove = ['dt_iso', 'timezone', 'lat', 'lon', 'weather_icon', 'weather_id', 'weather_main',\n",
    "                     'weather_description', 'visibility', 'wind_deg', 'feels_like', 'temp_min', 'temp_max']\n",
    "\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "    # remove features with majority null values\n",
    "    df_pct_null = df.isna().sum() / len(df)\n",
    "    cols_2_remove = list(df_pct_null[df_pct_null > 0.5].index)\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "    # remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    count_by_city = df.groupby('city_name').size()\n",
    "\n",
    "    # check that there are the same number of records per city\n",
    "    for i in range(len(count_by_city)):\n",
    "        if i > 0 and count_by_city.iloc[i] != count_by_city.iloc[0]:\n",
    "            city1, count1 = count_by_city.index[i - 1], count_by_city.iloc[i - 1]\n",
    "            city2, count2 = count_by_city.index[i], count_by_city.iloc[i]\n",
    "            print(f\"Different number of records for {city1}({count1}) vs {city2}({count2})\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    df = df.set_index(\"datetime\")\n",
    "\n",
    "    # set outliers to null\n",
    "    outlier_ind = []\n",
    "    outlier_ind.append((df['city_name'] == \"utrecht\") & (df['wind_speed'] > 21) & (df.index >= '2021-01-24') & (\n",
    "                df.index <= '2021-01-26'))\n",
    "    outlier_ind.append((df['city_name'] == \"utrecht\") & (df['wind_speed'] > 21) & (df.index >= '2021-03-10') & (\n",
    "                df.index <= '2021-03-20'))\n",
    "    outlier_ind.append((df['city_name'] == \"eindhoven\") & (df['wind_speed'] > 10) & (df.index >= '2022-11-16') & (\n",
    "                df.index <= '2022-11-25'))\n",
    "    outlier_ind.append((df['city_name'] == \"eindhoven\") & (df['wind_speed'] > 15) & (df.index >= '2023-01-13') & (\n",
    "                df.index <= '2023-01-15'))\n",
    "    outlier_ind.append((df['humidity'] < 18))\n",
    "    outlier_cols = [\"wind_speed\", \"wind_speed\", \"wind_speed\", \"wind_speed\", [\"dew_point\", \"humidity\"]]\n",
    "\n",
    "    for ind, cols in zip(outlier_ind, outlier_cols):\n",
    "        df.loc[ind, cols] = np.nan\n",
    "\n",
    "    cities = df[\"city_name\"].unique()\n",
    "\n",
    "    # create seperate column per feature and city\n",
    "    for i, city in enumerate(cities):\n",
    "        temp_df = df[df[\"city_name\"] == city].copy()\n",
    "        temp_df = temp_df.drop(\"city_name\", axis=1)\n",
    "        temp_df = temp_df.sort_index()\n",
    "        temp_df = temp_df.add_suffix(f'_{city}')\n",
    "        if i == 0:\n",
    "            df_wide = temp_df\n",
    "        else:\n",
    "            df_wide = pd.merge(df_wide, temp_df, left_index=True, how='left', right_index=True)\n",
    "\n",
    "    df = df_wide.copy()\n",
    "\n",
    "    del df_wide\n",
    "\n",
    "    # remove features with majority null values\n",
    "    df_pct_null = df.isna().sum() / len(df)\n",
    "    cols_2_remove = list(df_pct_null[df_pct_null > 0.5].index)\n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "\n",
    "    # interpolate remaining features\n",
    "    df.interpolate(method='linear', limit_direction='forward', inplace=True)\n",
    "\n",
    "    # Create weighted variable from highly correlated variables per city\n",
    "    corr_features = [\"dew_point\", \"temp\", \"pressure\", \"humidity\", \"wind_speed\"]\n",
    "    df = create_weighted_variables(df, corr_features, cities)\n",
    "    \n",
    "    # remove clouds_all featues except for clouds_all_amsterdam\n",
    "    cols_2_remove = ['clouds_all_almere', 'clouds_all_eindhoven', 'clouds_all_groningen', \n",
    "                     'clouds_all_rotterdam','clouds_all_the hague', 'clouds_all_utrecht'] \n",
    "    df = df.drop(cols_2_remove, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_unav_gen_data(df_names):\n",
    "    print(\"Preparing Unavailable Generation Data\")\n",
    "\n",
    "    for i, df_name in enumerate(df_names):\n",
    "        temp_df = pd.read_csv(f\".\\\\data\\\\unavailability_of_generation_units_NL_{df_name}.csv\")\n",
    "        temp_df[\"datetime\"] = pd.to_datetime(temp_df[\"datetime\"], utc=True).dt.tz_localize(None)\n",
    "        temp_df = temp_df.sort_values('datetime').set_index('datetime')\n",
    "        if i == 0:\n",
    "            df = temp_df.copy()\n",
    "        else:\n",
    "            df = pd.merge(df, temp_df, left_index=True, how='left', right_index=True)\n",
    "\n",
    "    return df.fillna(0)\n",
    "\n",
    "\n",
    "def generate_calendar_features(df, target_datetime):\n",
    "    df = df.copy()\n",
    "    print(\"Adding Calendar Features\")\n",
    "    df[\"target_hour_of_day\"] = target_datetime.dt.hour\n",
    "    df[\"target_day_of_week\"] = target_datetime.dt.dayofweek\n",
    "    df[\"target_weekend\"] = np.where((df[\"target_day_of_week\"] == 5) | (df[\"target_day_of_week\"] == 6), 1, 0)\n",
    "    df[\"target_month\"] = target_datetime.dt.month\n",
    "    # add variables for holidays\n",
    "    nl_holidays = holidays.NL()\n",
    "    df[\"target_holiday\"] = target_datetime.dt.date.apply(lambda x: nl_holidays.get(x)).values\n",
    "    df[\"target_is_holiday\"] = np.where(df[\"target_holiday\"].isna(), 0, 1)\n",
    "    df = pd.get_dummies(df, columns=[\"target_holiday\"], dummy_na=False)\n",
    "    df = df.drop([\"target_holiday_Bevrijdingsdag\", \"target_holiday_Koningsdag\"], axis=1)\n",
    "    holiday_cols = [col for col in df.columns if \"target_holiday_\" in col]\n",
    "    for col in holiday_cols:\n",
    "        df[col] = np.where(df[col], 1, 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_RLI_features(df, horizons):\n",
    "    df = df.copy()\n",
    "    print(\"Adding Relative Load Indicator Features\")\n",
    "    for h in horizons:\n",
    "        temp_residual_load_rs = df[\"residual_load\"].rolling(window=h, min_periods=h).sum().shift(1)\n",
    "        df[f\"RLI_{h}\"] = 100 * df[\"residual_load\"].div(temp_residual_load_rs)\n",
    "        del temp_residual_load_rs\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_lagged_features(df, features, lags):\n",
    "    lagged_data = []\n",
    "    for feature in features:\n",
    "        for lag in lags:\n",
    "            # df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "            lagged_data.append(df[feature].shift(lag))\n",
    "            lagged_data[-1].name = f'{feature}_lag_{lag}'\n",
    "\n",
    "    df = pd.concat([df] + lagged_data, axis=1)\n",
    "\n",
    "    return df.copy()\n",
    "\n",
    "\n",
    "def feature_generation(df):\n",
    "    df = df.reset_index()\n",
    "    # Negatively shift prices by 48hours so we forecast 48 hours into the future\n",
    "    print(\"Adding leading day_ahead_returns as target\")\n",
    "    df['day_ahead_prices_lead_48'] = df['day_ahead_prices'].shift(-48)\n",
    "    df['datetime_lead_48'] = df['datetime'].shift(-48)\n",
    "    df = df.dropna()\n",
    "    df = generate_calendar_features(df, df['datetime_lead_48'])\n",
    "    df = df.drop(['datetime_lead_48'], axis=1)\n",
    "    df = generate_RLI_features(df, [24, 48, 120])\n",
    "    print(\"Adding Lagged covariates\")\n",
    "    lags = [24, 48, 72, 96, 120]\n",
    "    features = [\n",
    "        'day_ahead_prices',\n",
    "        'generation_fossil_gas_missing_qty',\n",
    "        'generation_fossil_hard_coal_missing_qty',\n",
    "        ]\n",
    "    df = generate_lagged_features(df, features, lags)\n",
    "    lags = [120]\n",
    "    features = [\n",
    "        'generation_Biomass',\n",
    "        'generation_Fossil Gas',\n",
    "        'generation_Fossil Hard coal',\n",
    "        'generation_Nuclear',\n",
    "        'generation_Other',\n",
    "        'generation_Solar',\n",
    "        'generation_Waste',\n",
    "        'crossborder_flow_net',\n",
    "        'imports',\n",
    "        'Forecasted Load',\n",
    "        'generation_forecast',\n",
    "        'generation_forecast_Solar',\n",
    "        'generation_total',\n",
    "        'residual_load',\n",
    "        'generation_Wind',\n",
    "        'generation_forecast_Wind',\n",
    "        'clouds_all_amsterdam',\n",
    "        'dew_point_weighted',\n",
    "        'temp_weighted',\n",
    "        'pressure_weighted',\n",
    "        'humidity_weighted',\n",
    "        'wind_speed_weighted',\n",
    "        'generation_nuclear_missing_qty']\n",
    "    df = generate_lagged_features(df, features, lags)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbb7292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Data Preparation\n",
      "####################\n",
      "\n",
      "Preparing Energy Data\n",
      "Preparing Weather Data\n",
      "Preparing Unavailable Generation Data\n",
      "Merging Data\n",
      "\n",
      "Data Quality\n",
      "                                         pct_nulls  pct_zeros\n",
      "day_ahead_prices                               0.0        0.0\n",
      "generation_Biomass                             0.0       10.0\n",
      "generation_Fossil Gas                          0.0        0.0\n",
      "generation_Fossil Hard coal                    0.0        0.0\n",
      "generation_Nuclear                             0.0        0.0\n",
      "generation_Other                               0.0        0.0\n",
      "generation_Solar                               0.0       10.0\n",
      "generation_Waste                               0.0        0.0\n",
      "crossborder_flow_net                           0.0        0.0\n",
      "imports                                        0.0        0.0\n",
      "Forecasted Load                                0.0        0.0\n",
      "generation_forecast                            0.0        0.0\n",
      "generation_forecast_Solar                      0.0       40.0\n",
      "generation_total                               0.0        0.0\n",
      "residual_load                                  0.0        0.0\n",
      "generation_Wind                                0.0        0.0\n",
      "generation_forecast_Wind                       0.0        0.0\n",
      "clouds_all_amsterdam                           0.0       20.0\n",
      "dew_point_weighted                             0.0        0.0\n",
      "temp_weighted                                  0.0        0.0\n",
      "pressure_weighted                              0.0        0.0\n",
      "humidity_weighted                              0.0        0.0\n",
      "wind_speed_weighted                            0.0        0.0\n",
      "generation_fossil_gas_missing_qty              0.0        0.0\n",
      "generation_fossil_hard_coal_missing_qty        0.0       20.0\n",
      "generation_nuclear_missing_qty                 0.0       90.0\n",
      "####################\n",
      "Feature Generation\n",
      "####################\n",
      "\n",
      "Adding leading day_ahead_returns as target\n",
      "Adding Calendar Features\n",
      "Adding Relative Load Indicator Features\n",
      "Adding Lagged covariates\n"
     ]
    }
   ],
   "source": [
    "en_names = [    \n",
    "    \"day_ahead_prices\",\n",
    "    \"load\",\n",
    "    \"generation\",\n",
    "    \"crossborder_flow_net\",\n",
    "    \"imports\",\n",
    "    \"load_forecast\",\n",
    "    \"generation_forecast\",\n",
    "    \"wind_solar_forecast\",\n",
    "]\n",
    "\n",
    "gen_names = [    \n",
    "    \"fossil_gas\",\n",
    "    \"fossil_hard_coal\",\n",
    "    \"nuclear\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "print(\"#\" * 20)\n",
    "print(\"Data Preparation\")\n",
    "print(\"#\" * 20)\n",
    "print(\"\")\n",
    "dfs.append(prepare_en_data(en_names))\n",
    "dfs.append(prepare_weather_data(dfs[0].index.min(), dfs[0].index.max()))\n",
    "dfs.append(prepare_unav_gen_data(gen_names))\n",
    "\n",
    "print(\"Merging Data\")\n",
    "for i, temp_df in enumerate(dfs):\n",
    "    if i == 0:\n",
    "        df = temp_df.copy()\n",
    "    else:\n",
    "        df = pd.merge(df, temp_df, left_index=True, how='left', right_index=True)\n",
    "\n",
    "print(\"\\nData Quality\")\n",
    "df_nulls_zeros = pd.DataFrame()\n",
    "df_nulls_zeros[\"pct_nulls\"] = 100 * (df.isna().sum() / len(df)).to_frame().round(1)\n",
    "df_nulls_zeros[\"pct_zeros\"] = 100 * ((df == 0).sum() / len(df)).to_frame().round(1)\n",
    "print(df_nulls_zeros)\n",
    "\n",
    "print(\"#\" * 20)\n",
    "print(\"Feature Generation\")\n",
    "print(\"#\" * 20)\n",
    "print(\"\")\n",
    "df = feature_generation(df)\n",
    "\n",
    "df.to_csv(\".\\\\data\\\\prepped_data_NL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfcea93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                                           2020-01-06 00:00:00\n",
       "day_ahead_prices                                                  29.0\n",
       "generation_Biomass                                                39.0\n",
       "generation_Fossil Gas                                          20266.0\n",
       "generation_Fossil Hard coal                                     3528.0\n",
       "generation_Nuclear                                              1941.0\n",
       "generation_Other                                                6252.0\n",
       "generation_Solar                                                  -2.0\n",
       "generation_Waste                                                1656.0\n",
       "crossborder_flow_net                                             185.0\n",
       "imports                                                         2550.0\n",
       "Forecasted Load                                                37700.0\n",
       "generation_forecast                                             9847.0\n",
       "generation_forecast_Solar                                          0.0\n",
       "generation_total                                               53079.0\n",
       "residual_load                                                  40770.0\n",
       "generation_Wind                                                 4055.0\n",
       "generation_forecast_Wind                                        5497.0\n",
       "clouds_all_amsterdam                                               100\n",
       "dew_point_weighted                                            5.326381\n",
       "temp_weighted                                                 6.728191\n",
       "pressure_weighted                                           1030.00776\n",
       "humidity_weighted                                             90.76217\n",
       "wind_speed_weighted                                           3.975057\n",
       "generation_fossil_gas_missing_qty                               5195.0\n",
       "generation_fossil_hard_coal_missing_qty                         1693.0\n",
       "generation_nuclear_missing_qty                                     0.0\n",
       "day_ahead_prices_lead_48                                         25.77\n",
       "target_hour_of_day                                                   0\n",
       "target_day_of_week                                                   2\n",
       "target_weekend                                                       0\n",
       "target_month                                                         1\n",
       "target_is_holiday                                                    0\n",
       "target_holiday_Eerste Kerstdag                                       0\n",
       "target_holiday_Eerste Pinksterdag                                    0\n",
       "target_holiday_Eerste paasdag                                        0\n",
       "target_holiday_Hemelvaartsdag                                        0\n",
       "target_holiday_Nieuwjaarsdag                                         0\n",
       "target_holiday_Tweede Kerstdag                                       0\n",
       "target_holiday_Tweede Pinksterdag                                    0\n",
       "target_holiday_Tweede paasdag                                        0\n",
       "RLI_24                                                        3.628787\n",
       "RLI_48                                                        1.823552\n",
       "RLI_120                                                       0.712078\n",
       "day_ahead_prices_lag_24                                          32.28\n",
       "day_ahead_prices_lag_48                                          30.37\n",
       "day_ahead_prices_lag_72                                           27.7\n",
       "day_ahead_prices_lag_96                                          31.98\n",
       "day_ahead_prices_lag_120                                          38.6\n",
       "generation_fossil_gas_missing_qty_lag_24                        5195.0\n",
       "generation_fossil_gas_missing_qty_lag_48                        5195.0\n",
       "generation_fossil_gas_missing_qty_lag_72                        4185.0\n",
       "generation_fossil_gas_missing_qty_lag_96                        4185.0\n",
       "generation_fossil_gas_missing_qty_lag_120                       4185.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_24                   790.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_48                  1860.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_72                  1070.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_96                  1860.0\n",
       "generation_fossil_hard_coal_missing_qty_lag_120                 1070.0\n",
       "generation_Biomass_lag_120                                         9.0\n",
       "generation_Fossil Gas_lag_120                                   5800.0\n",
       "generation_Fossil Hard coal_lag_120                             2013.0\n",
       "generation_Nuclear_lag_120                                       485.0\n",
       "generation_Other_lag_120                                        1206.0\n",
       "generation_Solar_lag_120                                          -1.0\n",
       "generation_Waste_lag_120                                         444.0\n",
       "crossborder_flow_net_lag_120                                     918.0\n",
       "imports_lag_120                                                 1764.0\n",
       "Forecasted Load_lag_120                                         9409.0\n",
       "generation_forecast_lag_120                                     7320.0\n",
       "generation_forecast_Solar_lag_120                                  0.0\n",
       "generation_total_lag_120                                       17846.0\n",
       "residual_load_lag_120                                          11004.0\n",
       "generation_Wind_lag_120                                          219.0\n",
       "generation_forecast_Wind_lag_120                                 351.0\n",
       "clouds_all_amsterdam_lag_120                                      75.0\n",
       "dew_point_weighted_lag_120                                    2.156217\n",
       "temp_weighted_lag_120                                         2.853168\n",
       "pressure_weighted_lag_120                                       1035.0\n",
       "humidity_weighted_lag_120                                    95.170093\n",
       "wind_speed_weighted_lag_120                                   3.298358\n",
       "generation_nuclear_missing_qty_lag_120                             0.0\n",
       "Name: 120, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
